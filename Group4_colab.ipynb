{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "c_bLVK_UFTXh"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# Unmount Google Drive\n",
    "# drive.flush_and_unmount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YG54tpNQidpK"
   },
   "source": [
    "**Required modules**\n",
    "---\n",
    "\n",
    "\n",
    "1.   attackcti\n",
    "2.   mitreattack-python library\n",
    "3.   scikit-learn\n",
    "4.   imblanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZidg7SkXcvb",
    "outputId": "caa01afa-8838-49c7-d7c2-8ba3b02255af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: attackcti in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.4.4)\n",
      "Requirement already satisfied: stix2 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from attackcti) (3.0.1)\n",
      "Requirement already satisfied: taxii2-client in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from attackcti) (2.3.0)\n",
      "Requirement already satisfied: pydantic in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from attackcti) (2.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic->attackcti) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic->attackcti) (2.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic->attackcti) (4.9.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix2->attackcti) (2024.1)\n",
      "Requirement already satisfied: requests in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix2->attackcti) (2.31.0)\n",
      "Requirement already satisfied: simplejson in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix2->attackcti) (3.19.2)\n",
      "Requirement already satisfied: stix2-patterns>=1.2.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix2->attackcti) (2.0.0)\n",
      "Requirement already satisfied: six in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from taxii2-client->attackcti) (1.16.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime~=4.9.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix2-patterns>=1.2.0->stix2->attackcti) (4.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->stix2->attackcti) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->stix2->attackcti) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->stix2->attackcti) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->stix2->attackcti) (2024.2.2)\n",
      "Requirement already satisfied: mitreattack-python in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.8)\n",
      "Requirement already satisfied: colour in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (0.1.5)\n",
      "Requirement already satisfied: deepdiff in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (8.0.1)\n",
      "Requirement already satisfied: drawsvg>=2.0.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (2.4.0)\n",
      "Requirement already satisfied: loguru in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (0.7.2)\n",
      "Requirement already satisfied: Markdown in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (3.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (2.1.3)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (3.1.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (2.2.3)\n",
      "Requirement already satisfied: pooch in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (1.8.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\tzhiq\\appdata\\roaming\\python\\python312\\site-packages (from mitreattack-python) (2.9.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (11.0.0)\n",
      "Requirement already satisfied: requests in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (2.31.0)\n",
      "Requirement already satisfied: rich in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (13.9.4)\n",
      "Requirement already satisfied: stix2 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (3.0.1)\n",
      "Requirement already satisfied: stix2-elevator in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (4.1.7)\n",
      "Requirement already satisfied: tabulate in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (0.9.0)\n",
      "Requirement already satisfied: taxii2-client in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (2.3.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (4.67.1)\n",
      "Requirement already satisfied: typer in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (0.13.1)\n",
      "Requirement already satisfied: xlsxwriter in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mitreattack-python) (3.2.0)\n",
      "Requirement already satisfied: orderly-set==5.2.2 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from deepdiff->mitreattack-python) (5.2.2)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from loguru->mitreattack-python) (0.4.6)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from loguru->mitreattack-python) (1.1.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl->mitreattack-python) (2.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->mitreattack-python) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->mitreattack-python) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil->mitreattack-python) (1.16.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch->mitreattack-python) (3.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch->mitreattack-python) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->mitreattack-python) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->mitreattack-python) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->mitreattack-python) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->mitreattack-python) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->mitreattack-python) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->mitreattack-python) (2.17.2)\n",
      "Requirement already satisfied: simplejson in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix2->mitreattack-python) (3.19.2)\n",
      "Requirement already satisfied: stix2-patterns>=1.2.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix2->mitreattack-python) (2.0.0)\n",
      "Requirement already satisfied: maec in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix2-elevator->mitreattack-python) (4.1.0.17)\n",
      "Requirement already satisfied: netaddr in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix2-elevator->mitreattack-python) (1.3.0)\n",
      "Requirement already satisfied: pycountry>=20.7.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix2-elevator->mitreattack-python) (24.6.1)\n",
      "Requirement already satisfied: pluralizer in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix2-elevator->mitreattack-python) (1.2.0)\n",
      "Requirement already satisfied: stix<1.2.1.0,>=1.1.1.9 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix2-elevator->mitreattack-python) (1.2.0.11)\n",
      "Requirement already satisfied: stix2-validator>=3.0.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix2-elevator->mitreattack-python) (3.2.0)\n",
      "Requirement already satisfied: stixmarx>=1.0.8 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix2-elevator->mitreattack-python) (1.0.8)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer->mitreattack-python) (8.1.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer->mitreattack-python) (4.9.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer->mitreattack-python) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->mitreattack-python) (0.1.2)\n",
      "Requirement already satisfied: mixbox>=1.0.4 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix<1.2.1.0,>=1.1.1.9->stix2-elevator->mitreattack-python) (1.0.5)\n",
      "Requirement already satisfied: cybox<2.1.1.0,>=2.1.0.13 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix<1.2.1.0,>=1.1.1.9->stix2-elevator->mitreattack-python) (2.1.0.21)\n",
      "Requirement already satisfied: lxml>=2.2.3 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix<1.2.1.0,>=1.1.1.9->stix2-elevator->mitreattack-python) (5.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime~=4.9.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix2-patterns>=1.2.0->stix2->mitreattack-python) (4.9.3)\n",
      "Requirement already satisfied: cpe in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stix2-validator>=3.0.0->stix2-elevator->mitreattack-python) (1.3.1)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python) (4.23.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=4.20.0->jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=4.20.0->jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=4.20.0->jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=4.20.0->jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python) (0.21.0)\n",
      "Requirement already satisfied: fqdn in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python) (3.0.0)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>0.1.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python) (0.1.1)\n",
      "Requirement already satisfied: uri-template in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python) (24.11.1)\n",
      "Requirement already satisfied: ordered-set in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mixbox>=1.0.4->stix<1.2.1.0,>=1.1.1.9->stix2-elevator->mitreattack-python) (4.1.0)\n",
      "Requirement already satisfied: weakrefmethod>=1.0.3 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mixbox>=1.0.4->stix<1.2.1.0,>=1.1.1.9->stix2-elevator->mitreattack-python) (1.0.3)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python) (2.9.0.20241003)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\tzhiq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n"
     ]
    }
   ],
   "source": [
    "# install library to interact with mitre attack framework\n",
    "!pip install attackcti \n",
    "!pip install mitreattack-python\n",
    "!pip install scikit-learn\n",
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "geyZo648ZdMd",
    "outputId": "07185ef0-6805-417d-f1fd-c2361bdf8877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: mitreattack-python\n",
      "Version: 3.0.8\n",
      "Summary: MITRE ATT&CK python library\n",
      "Home-page: https://github.com/mitre-attack/mitreattack-python/\n",
      "Author: MITRE ATT&CK, MITRE Corporation\n",
      "Author-email: attack@mitre.org"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "License: Apache 2.0\n",
      "Location: C:\\Users\\tzhiq\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\n",
      "Requires: colour, deepdiff, drawsvg, loguru, Markdown, numpy, openpyxl, pandas, Pillow, pooch, python-dateutil, requests, rich, stix2, stix2-elevator, tabulate, taxii2-client, tqdm, typer, xlsxwriter\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show mitreattack-python\n",
    "# !ls /usr/local/lib/python3.10/dist-packages/mitreattack/\n",
    "# help() #will ask to type in module , from here we can type in mitreattack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gg68zL7gjHWc"
   },
   "source": [
    "**Retrieve Dataset using mitreattack-python library**\n",
    "---\n",
    "Dataset Description\n",
    "\n",
    "---\n",
    "1.   apt_groups: List of groups found in Mitre Attack framework\n",
    "2.   attack_relationships: List of all the relationship listed in Mitre Attack framework\n",
    "3.   attack_techniques: List of all the techniques listed in Mitre Attack framework\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8jSqqrs2txZc",
    "outputId": "45e649fd-63a3-4a9e-8e0f-a830f21218b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-26 18:42:48.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmitreattack.attackToExcel.attackToExcel\u001b[0m:\u001b[36mget_stix_data\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mDownloading ATT&CK data from github.com/mitre/cti\u001b[0m\n",
      "parsing techniques: 100%|██████████| 656/656 [00:00<00:00, 2877.48it/s]\n",
      "parsing relationships for type=technique: 100%|██████████| 19163/19163 [00:00<00:00, 24838.70it/s]\n",
      "parsing groups: 100%|██████████| 159/159 [00:00<00:00, 74839.45it/s]\n",
      "parsing relationships for type=group: 100%|██████████| 19163/19163 [00:00<00:00, 104484.93it/s]\n",
      "parsing all relationships: 100%|██████████| 19163/19163 [00:00<00:00, 25248.83it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '\\content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Step 3: Save the DataFrame to a CSV file respectively\u001b[39;00m\n\u001b[0;32m     16\u001b[0m techniques_csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/attack_techniques.csv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# Replace with your file path\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43mdf_techniques\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtechniques_csv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTechnique CSV file created at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtechniques_csv_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m groups_csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/apt_groups.csv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# Replace with your file path\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tzhiq\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tzhiq\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tzhiq\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\tzhiq\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\tzhiq\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tzhiq\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '\\content'"
     ]
    }
   ],
   "source": [
    "from mitreattack.attackToExcel import attackToExcel, stixToDf\n",
    "\n",
    "# Step 1: Download and parse ATT&CK STIX data\n",
    "attackdata = attackToExcel.get_stix_data(\"enterprise-attack\")\n",
    "\n",
    "# Step 2: Get Pandas DataFrame for techniques, groups & relationship\n",
    "techniques_data = stixToDf.techniquesToDf(attackdata, \"enterprise-attack\")\n",
    "groups_data = stixToDf.groupsToDf(attackdata)\n",
    "relationships_data = stixToDf.relationshipsToDf(attackdata)\n",
    "\n",
    "df_techniques = techniques_data[\"techniques\"]\n",
    "df_groups = groups_data[\"groups\"]\n",
    "df_relationships = relationships_data[\"relationships\"]\n",
    "\n",
    "# Step 3: Save the DataFrame to a CSV file respectively\n",
    "techniques_csv_file = '/content/attack_techniques.csv' # Replace with your file path\n",
    "df_techniques.to_csv(techniques_csv_file, index=False)\n",
    "print(f\"Technique CSV file created at: {techniques_csv_file}\")\n",
    "\n",
    "groups_csv_file = '/content/apt_groups.csv' # Replace with your file path\n",
    "df_groups.to_csv(groups_csv_file, index=False)\n",
    "print(f\"Group CSV file created at: {groups_csv_file}\")\n",
    "\n",
    "relationships_csv_file = '/content/attack_relationships.csv' # Replace with your file path\n",
    "df_relationships.to_csv(relationships_csv_file, index=False)\n",
    "print(f\"Relationship CSV file created at: {relationships_csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kNMIKgumUf44",
    "outputId": "a608a392-957a-4289-8dc5-27d51b88943c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID                                            STIX ID  \\\n",
      "0      T1548  attack-pattern--67720091-eee3-4d2d-ae16-826456...   \n",
      "1  T1548.002  attack-pattern--120d5519-3098-4e1c-9191-2aa612...   \n",
      "2  T1548.004  attack-pattern--b84903f0-c7d5-435d-a69e-de47cc...   \n",
      "3  T1548.001  attack-pattern--6831414d-bb70-42b7-8030-d4e06b...   \n",
      "4  T1548.003  attack-pattern--1365fe3b-0f50-455d-b4da-266ce3...   \n",
      "\n",
      "                                                name  \\\n",
      "0                  Abuse Elevation Control Mechanism   \n",
      "1  Abuse Elevation Control Mechanism: Bypass User...   \n",
      "2  Abuse Elevation Control Mechanism: Elevated Ex...   \n",
      "3  Abuse Elevation Control Mechanism: Setuid and ...   \n",
      "4  Abuse Elevation Control Mechanism: Sudo and Su...   \n",
      "\n",
      "                                         description  \\\n",
      "0  Adversaries may circumvent mechanisms designed...   \n",
      "1  Adversaries may bypass UAC mechanisms to eleva...   \n",
      "2  Adversaries may leverage the <code>Authorizati...   \n",
      "3  An adversary may abuse configurations where an...   \n",
      "4  Adversaries may perform sudo caching and/or us...   \n",
      "\n",
      "                                             url          created  \\\n",
      "0      https://attack.mitre.org/techniques/T1548  30 January 2020   \n",
      "1  https://attack.mitre.org/techniques/T1548/002  30 January 2020   \n",
      "2  https://attack.mitre.org/techniques/T1548/004  30 January 2020   \n",
      "3  https://attack.mitre.org/techniques/T1548/001  30 January 2020   \n",
      "4  https://attack.mitre.org/techniques/T1548/003  30 January 2020   \n",
      "\n",
      "     last modified             domain  version  \\\n",
      "0  15 October 2024  enterprise-attack      1.4   \n",
      "1    21 April 2023  enterprise-attack      2.1   \n",
      "2  19 October 2022  enterprise-attack      1.0   \n",
      "3    15 March 2023  enterprise-attack      1.1   \n",
      "4    14 March 2022  enterprise-attack      1.0   \n",
      "\n",
      "                                 tactics  ... is sub-technique  \\\n",
      "0  Defense Evasion, Privilege Escalation  ...            False   \n",
      "1  Defense Evasion, Privilege Escalation  ...             True   \n",
      "2  Defense Evasion, Privilege Escalation  ...             True   \n",
      "3  Defense Evasion, Privilege Escalation  ...             True   \n",
      "4  Defense Evasion, Privilege Escalation  ...             True   \n",
      "\n",
      "  sub-technique of             defenses bypassed  \\\n",
      "0              NaN                           NaN   \n",
      "1            T1548  Windows User Account Control   \n",
      "2            T1548                           NaN   \n",
      "3            T1548                           NaN   \n",
      "4            T1548                           NaN   \n",
      "\n",
      "                                        contributors permissions required  \\\n",
      "0                                                NaN  Administrator, User   \n",
      "1                        Casey Smith; Stefan Kanthak  Administrator, User   \n",
      "2  Erika Noerenberg, @gutterchurl, Carbon Black; ...  Administrator, User   \n",
      "3                                                NaN                 User   \n",
      "4                                                NaN                 User   \n",
      "\n",
      "  supports remote system requirements impact type effective permissions  \\\n",
      "0             NaN                 NaN         NaN                   NaN   \n",
      "1             NaN                 NaN         NaN         Administrator   \n",
      "2             NaN                 NaN         NaN                  root   \n",
      "3             NaN                 NaN         NaN                   NaN   \n",
      "4             NaN                 NaN         NaN                  root   \n",
      "\n",
      "                              relationship citations  \n",
      "0  (Citation: TrendMicro RaspberryRobin 2022),(Ci...  \n",
      "1  (Citation: Proofpoint ZeroT Feb 2017),(Citatio...  \n",
      "2         (Citation: Carbon Black Shlayer Feb 2019),  \n",
      "3  (Citation: OSX Keydnap malware),(Citation: ANS...  \n",
      "4  (Citation: Cobalt Strike Manual 4.3 November 2...  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Optional - Verify the CSV content\n",
    "import pandas as pd\n",
    "df = pd.read_csv(techniques_csv_file)\n",
    "print(df.head())  # Display the first few rows to verify the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhyeurF1bTnT"
   },
   "source": [
    "**Data Preprocessing**\n",
    "---\n",
    "\n",
    "\n",
    "*   Identify Key Features\n",
    "*   Remove any unnecessary columns\n",
    "*   Handle missing values\n",
    "*   Normalize text fields\n",
    "\n",
    "1.   aptgroup_relationship.csv: Filtered list of all techniques that are used by each APT group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_2F9FQzqqLO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSVs\n",
    "techniques_df = pd.read_csv(techniques_csv_file)\n",
    "relationships_df = pd.read_csv(relationships_csv_file)\n",
    "groups_df = pd.read_csv(groups_csv_file)\n",
    "\n",
    "# Replace empty strings or strings with only spaces with NaN\n",
    "techniques_df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "techniques_df[\"supports remote\"] = techniques_df[\"supports remote\"].fillna(\"FALSE\")\n",
    "relationships_df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "groups_df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "\n",
    "# Columns to drop in each csv file\n",
    "techniques_dropped_columns = [\"STIX ID\", \"created\", \"url\", \"last modified\", \"domain\", \"version\", \"detection\", \"data sources\", \"contributors\", \"defenses bypassed\", \"permissions required\", \"system requirements\", \"impact type\", \"effective permissions\", \"relationship citations\"]\n",
    "relationships_dropped_columns = [\"source ref\", \"source type\", \"mapping type\", \"target ref\", \"target type\", \"STIX ID\", \"created\", \"last modified\"]\n",
    "groups_dropped_columns = [\"STIX ID\", \"created\", \"url\", \"last modified\", \"domain\", \"version\", \"contributors\", \"associated groups\", \"associated groups citations\", \"relationship citations\"]\n",
    "\n",
    "# Drop the columns in each csv file\n",
    "techniques_df = techniques_df.drop(columns=techniques_dropped_columns)\n",
    "relationships_df = relationships_df.drop(columns=relationships_dropped_columns)\n",
    "groups_df = groups_df.drop(columns=groups_dropped_columns)\n",
    "\n",
    "# Filter rows where the source ID starts with \"G\" and target ID starts with \"T\" in relationship.csv\n",
    "# Find techniques that are used by each APT group\n",
    "aptgroup_relationships_df = relationships_df[\n",
    "    relationships_df['source ID'].str.startswith('G') & relationships_df['target ID'].str.startswith('T')\n",
    "]\n",
    "\n",
    "# Save the modified CSV\n",
    "techniques_df.to_csv('/content/attack_techniques_cleaned.csv', index=False) # Replace with your file path\n",
    "relationships_df.to_csv('/content/attack_relationships_cleaned.csv', index=False) # Replace with your file path\n",
    "groups_df.to_csv('/content/apt_groups_cleaned.csv', index=False) # Replace with your file path\n",
    "aptgroup_relationships_df.to_csv('/content/aptgroup_relationships.csv', index=False) # Replace with your file path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "meOyyKtAdfQB",
    "outputId": "b6cb2fc5-a5eb-41de-a0eb-291b7c2efcc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  group ID group name technique ID                   technique name  \\\n",
      "0    G0099   APT-C-36        T1105            Ingress Tool Transfer   \n",
      "1    G0099   APT-C-36    T1204.002                   Malicious File   \n",
      "2    G0099   APT-C-36    T1036.004       Masquerade Task or Service   \n",
      "3    G0099   APT-C-36        T1571                Non-Standard Port   \n",
      "4    G0099   APT-C-36        T1027  Obfuscated Files or Information   \n",
      "\n",
      "                           group mapping description  \\\n",
      "0  [APT-C-36](https://attack.mitre.org/groups/G00...   \n",
      "1  [APT-C-36](https://attack.mitre.org/groups/G00...   \n",
      "2  [APT-C-36](https://attack.mitre.org/groups/G00...   \n",
      "3  [APT-C-36](https://attack.mitre.org/groups/G00...   \n",
      "4  [APT-C-36](https://attack.mitre.org/groups/G00...   \n",
      "\n",
      "                               technique description    technique tactics  \\\n",
      "0  Adversaries may transfer tools or other files ...  Command and Control   \n",
      "1  An adversary may rely upon a user opening a ma...            Execution   \n",
      "2  Adversaries may attempt to manipulate the name...      Defense Evasion   \n",
      "3  Adversaries may communicate using a protocol a...  Command and Control   \n",
      "4  Adversaries may attempt to make an executable ...      Defense Evasion   \n",
      "\n",
      "              technique platforms  is sub-technique of target  \\\n",
      "0  Linux, Network, Windows, macOS                       False   \n",
      "1           Linux, Windows, macOS                        True   \n",
      "2           Linux, Windows, macOS                        True   \n",
      "3           Linux, Windows, macOS                       False   \n",
      "4  Linux, Network, Windows, macOS                       False   \n",
      "\n",
      "  target sub-technique of technique supports remote  \n",
      "0                     NaN                     FALSE  \n",
      "1                   T1204                     False  \n",
      "2                   T1036                     FALSE  \n",
      "3                     NaN                     FALSE  \n",
      "4                     NaN                     FALSE  \n"
     ]
    }
   ],
   "source": [
    "# Combine apt_groups_relationship with attack_techniques\n",
    "# Define the column names for the common key in each file\n",
    "techniques_key = 'ID'  # Column name in techniques.csv\n",
    "apt_groups_key = 'target ID'  # Column name in apt_groups.csv\n",
    "\n",
    "# Define the columns to merge and their new names\n",
    "columns_to_merge = {\n",
    "    'description': 'technique description',\n",
    "    'tactics': 'technique tactics',\n",
    "    'platforms': 'technique platforms',\n",
    "    'is sub-technique': 'is sub-technique of target',\n",
    "    'sub-technique of': 'target sub-technique of',\n",
    "    'supports remote': 'technique supports remote'\n",
    "}\n",
    "\n",
    "# Select only the necessary columns from techniques.csv\n",
    "columns_to_keep = [techniques_key] + list(columns_to_merge.keys())\n",
    "techniques_subset = techniques_df[columns_to_keep]\n",
    "\n",
    "# Merge the DataFrames\n",
    "updated_aptgroup_relationships_df = pd.merge(\n",
    "    aptgroup_relationships_df,\n",
    "    techniques_subset,\n",
    "    how='left',\n",
    "    left_on=apt_groups_key,\n",
    "    right_on=techniques_key\n",
    ")\n",
    "\n",
    "# Rename the columns as defined in columns_to_merge\n",
    "updated_aptgroup_relationships_df.rename(columns=columns_to_merge, inplace=True)\n",
    "\n",
    "# Optionally, drop the redundant key column from techniques.csv\n",
    "updated_aptgroup_relationships_df.drop(columns=[techniques_key], inplace=True)\n",
    "\n",
    "# Rename the columns for better reading of csv\n",
    "updated_aptgroup_relationships_df.rename(columns={'source ID': 'group ID'}, inplace=True)\n",
    "updated_aptgroup_relationships_df.rename(columns={'source name': 'group name'}, inplace=True)\n",
    "updated_aptgroup_relationships_df.rename(columns={'target ID': 'technique ID'}, inplace=True)\n",
    "updated_aptgroup_relationships_df.rename(columns={'target name': 'technique name'}, inplace=True)\n",
    "updated_aptgroup_relationships_df.rename(columns={'mapping description': 'group mapping description'}, inplace=True)\n",
    "updated_aptgroup_relationships_df.rename(columns={'target name': 'technique name'}, inplace=True)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "updated_aptgroup_relationships_df.to_csv('/content/updated_aptgroup_relationships.csv', index=False) # Replace with your file path\n",
    "\n",
    "# Print the first few rows to verify\n",
    "print(updated_aptgroup_relationships_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKuwtcc3lAkX"
   },
   "source": [
    "# **Random Forest**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kr43lGXRZYl-"
   },
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fniZiHM9zyM2"
   },
   "outputs": [],
   "source": [
    "# Load the updated dataset\n",
    "file_path = 'updated_aptgroup_relationships.csv' # Replace with your file path\n",
    "updated_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HR9BZE1uz7IR"
   },
   "source": [
    "# Sub-Technique Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DjGrgVGkbinq",
    "outputId": "82744bad-b0cc-4a17-ae93-401da5b4afdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sub-Technique Classification ===\n",
      "Accuracy: 0.9770114942528736\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       431\n",
      "           1       0.98      0.98      0.98       700\n",
      "\n",
      "    accuracy                           0.98      1131\n",
      "   macro avg       0.98      0.97      0.98      1131\n",
      "weighted avg       0.98      0.98      0.98      1131\n",
      "\n",
      "\n",
      "Feature Importances:\n",
      "               Feature  Importance\n",
      "1         technique ID    0.505340\n",
      "3  technique platforms    0.227755\n",
      "2    technique tactics    0.203007\n",
      "0             group ID    0.063899\n"
     ]
    }
   ],
   "source": [
    "# Define features and target for classification\n",
    "features = updated_df[[\"group ID\", \"technique ID\", \"technique tactics\", \"technique platforms\"]].copy()\n",
    "target = updated_df[\"is sub-technique of target\"].astype(int)  # Binary classification\n",
    "\n",
    "# Encode non-numeric features\n",
    "non_numeric_cols = features.select_dtypes(include=['object']).columns.tolist()\n",
    "for col in non_numeric_cols:\n",
    "    features[col] = features[col].astype('category').cat.codes\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Classifier\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print Results\n",
    "print(\"\\n=== Sub-Technique Classification ===\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "# Feature Importance\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"Feature\": features.columns,\n",
    "    \"Importance\": rf_classifier.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsWPXfF-z-Se"
   },
   "source": [
    "# Sub-Technique to Main Technique Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OwyZ97ON0HSr",
    "outputId": "2ca45849-56da-4812-9152-53e11ce6ea02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 35.78%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         7\n",
      "           4       0.06      1.00      0.12         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.00      0.00      0.00         2\n",
      "           9       1.00      1.00      1.00         4\n",
      "          11       0.00      0.00      0.00        12\n",
      "          12       0.00      0.00      0.00         8\n",
      "          13       0.12      1.00      0.22         3\n",
      "          15       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         3\n",
      "          18       0.00      0.00      0.00         6\n",
      "          19       0.00      0.00      0.00         4\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.05      1.00      0.10         2\n",
      "          22       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         9\n",
      "          27       0.00      0.00      0.00        11\n",
      "          28       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00         2\n",
      "          31       0.00      0.00      0.00         6\n",
      "          32       0.64      1.00      0.78        21\n",
      "          34       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.60      1.00      0.75         3\n",
      "          40       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.90      1.00      0.95         9\n",
      "          44       0.00      0.00      0.00         4\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.30      1.00      0.46         3\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00        10\n",
      "          50       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.46      1.00      0.63        28\n",
      "          54       0.00      0.00      0.00        14\n",
      "          55       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00        12\n",
      "          57       0.00      0.00      0.00         3\n",
      "          58       0.00      0.00      0.00         2\n",
      "          59       0.00      0.00      0.00         1\n",
      "          61       0.50      1.00      0.67         2\n",
      "          62       0.00      0.00      0.00         2\n",
      "          63       0.16      1.00      0.28         4\n",
      "          65       0.00      0.00      0.00         3\n",
      "          66       0.00      0.00      0.00        15\n",
      "          68       0.00      0.00      0.00         2\n",
      "          69       0.00      0.00      0.00         1\n",
      "          70       0.00      0.00      0.00        16\n",
      "          71       0.00      0.00      0.00         3\n",
      "          72       0.00      0.00      0.00         4\n",
      "          73       0.12      1.00      0.21         3\n",
      "          74       0.80      1.00      0.89         8\n",
      "          75       0.00      0.00      0.00         2\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       0.36      1.00      0.53         4\n",
      "          78       0.00      0.00      0.00         5\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         3\n",
      "          81       0.00      0.00      0.00         6\n",
      "          82       0.10      1.00      0.18         1\n",
      "          84       0.00      0.00      0.00         2\n",
      "          85       0.43      1.00      0.60         3\n",
      "          86       0.00      0.00      0.00         2\n",
      "          88       0.00      0.00      0.00         2\n",
      "          90       0.00      0.00      0.00         2\n",
      "          92       0.33      1.00      0.50         2\n",
      "          93       0.00      0.00      0.00         3\n",
      "          94       0.43      1.00      0.60         3\n",
      "          95       0.00      0.00      0.00         1\n",
      "          97       0.00      0.00      0.00         1\n",
      "          98       0.86      1.00      0.92         6\n",
      "         100       0.00      0.00      0.00         2\n",
      "         101       0.38      1.00      0.55         3\n",
      "         102       0.00      0.00      0.00         3\n",
      "         103       0.60      1.00      0.75         3\n",
      "         104       0.00      0.00      0.00         1\n",
      "         105       0.00      0.00      0.00         1\n",
      "         107       0.00      0.00      0.00         4\n",
      "         108       0.17      1.00      0.29         1\n",
      "         109       0.00      0.00      0.00         1\n",
      "         114       1.00      1.00      1.00         2\n",
      "         115       0.00      0.00      0.00        12\n",
      "         116       0.62      1.00      0.76        21\n",
      "         118       0.00      0.00      0.00         1\n",
      "         119       0.00      0.00      0.00         1\n",
      "         120       0.00      0.00      0.00         3\n",
      "         122       0.20      1.00      0.33         1\n",
      "         124       0.00      0.00      0.00         1\n",
      "         125       0.00      0.00      0.00         1\n",
      "         127       0.00      0.00      0.00         5\n",
      "         128       0.00      0.00      0.00         2\n",
      "         130       0.17      1.00      0.29         4\n",
      "         131       0.00      0.00      0.00        11\n",
      "         133       0.50      1.00      0.67         1\n",
      "         134       0.00      0.00      0.00         1\n",
      "         135       0.50      1.00      0.67         1\n",
      "         136       0.00      0.00      0.00         1\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         1\n",
      "         139       0.00      0.00      0.00         3\n",
      "         140       0.67      1.00      0.80         2\n",
      "         141       0.00      0.00      0.00         1\n",
      "         142       1.00      1.00      1.00        10\n",
      "         143       1.00      1.00      1.00         6\n",
      "         146       0.00      0.00      0.00         1\n",
      "         147       0.89      1.00      0.94         8\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       0.33      1.00      0.50         3\n",
      "         150       0.00      0.00      0.00         2\n",
      "         151       0.00      0.00      0.00         1\n",
      "         152       0.00      0.00      0.00         1\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       0.00      0.00      0.00        13\n",
      "         156       0.06      1.00      0.12         1\n",
      "         157       0.00      0.00      0.00         2\n",
      "         159       1.00      1.00      1.00         3\n",
      "         161       0.50      1.00      0.67         2\n",
      "         162       0.00      0.00      0.00         2\n",
      "         164       0.50      1.00      0.67         4\n",
      "         165       0.00      0.00      0.00         1\n",
      "         166       0.00      0.00      0.00         2\n",
      "         168       0.00      0.00      0.00         1\n",
      "         170       0.82      1.00      0.90         9\n",
      "         171       0.00      0.00      0.00         1\n",
      "         172       0.00      0.00      0.00         1\n",
      "         173       0.00      0.00      0.00         6\n",
      "         174       0.09      1.00      0.17         1\n",
      "         175       0.00      0.00      0.00         1\n",
      "         176       0.00      0.00      0.00         1\n",
      "         177       0.00      0.00      0.00         1\n",
      "         179       0.00      0.00      0.00         1\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         1\n",
      "         184       0.00      0.00      0.00         1\n",
      "         185       0.00      0.00      0.00         0\n",
      "         186       0.00      0.00      0.00         1\n",
      "         187       0.75      1.00      0.86         3\n",
      "         188       0.86      1.00      0.92        12\n",
      "         190       0.00      0.00      0.00         2\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         1\n",
      "         193       0.00      0.00      0.00        11\n",
      "         194       0.00      0.00      0.00         1\n",
      "         195       0.00      0.00      0.00         1\n",
      "         196       0.07      1.00      0.12         1\n",
      "         198       0.00      0.00      0.00         1\n",
      "         201       0.00      0.00      0.00         1\n",
      "         202       0.00      0.00      0.00         4\n",
      "         204       0.00      0.00      0.00         0\n",
      "         207       0.00      0.00      0.00         1\n",
      "         210       0.00      0.00      0.00        17\n",
      "         211       0.00      0.00      0.00         9\n",
      "         212       0.13      1.00      0.24         4\n",
      "         213       1.00      1.00      1.00        10\n",
      "         214       0.50      1.00      0.67         1\n",
      "         216       0.00      0.00      0.00         1\n",
      "         217       1.00      1.00      1.00         5\n",
      "         218       0.00      0.00      0.00         6\n",
      "         219       0.25      1.00      0.40         2\n",
      "         220       0.00      0.00      0.00         4\n",
      "         221       0.00      0.00      0.00         6\n",
      "         222       0.08      1.00      0.14         1\n",
      "         223       0.00      0.00      0.00         1\n",
      "         225       0.00      0.00      0.00         1\n",
      "         227       0.00      0.00      0.00        10\n",
      "         228       0.00      0.00      0.00         1\n",
      "         229       0.11      1.00      0.20         2\n",
      "         231       0.00      0.00      0.00         5\n",
      "         233       0.00      0.00      0.00         1\n",
      "         236       0.33      1.00      0.50         1\n",
      "         238       0.00      0.00      0.00         1\n",
      "         240       0.25      1.00      0.40         2\n",
      "         241       0.00      0.00      0.00         6\n",
      "         243       1.00      1.00      1.00         3\n",
      "         245       0.00      0.00      0.00         6\n",
      "         246       0.00      0.00      0.00         1\n",
      "         247       0.00      0.00      0.00         0\n",
      "         249       0.00      0.00      0.00         6\n",
      "         250       0.00      0.00      0.00        19\n",
      "         251       0.04      1.00      0.07         1\n",
      "         253       0.00      0.00      0.00         1\n",
      "         255       0.00      0.00      0.00         1\n",
      "         256       0.67      1.00      0.80         4\n",
      "         257       0.00      0.00      0.00         1\n",
      "         259       0.00      0.00      0.00         1\n",
      "         260       0.33      1.00      0.50         1\n",
      "         261       0.00      0.00      0.00         1\n",
      "         263       0.00      0.00      0.00         0\n",
      "         264       0.00      0.00      0.00         1\n",
      "         265       0.50      1.00      0.67         1\n",
      "         266       0.00      0.00      0.00         1\n",
      "         270       0.00      0.00      0.00         0\n",
      "         271       0.00      0.00      0.00         5\n",
      "         272       0.00      0.00      0.00         2\n",
      "         276       0.00      0.00      0.00         3\n",
      "         277       0.00      0.00      0.00         0\n",
      "         278       0.47      1.00      0.64         8\n",
      "         279       0.00      0.00      0.00         1\n",
      "         280       0.00      0.00      0.00         5\n",
      "         281       0.00      0.00      0.00         1\n",
      "         282       0.00      0.00      0.00         1\n",
      "         283       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.36       721\n",
      "   macro avg       0.13      0.28      0.16       721\n",
      "weighted avg       0.22      0.36      0.26       721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter for sub-techniques and create a copy\n",
    "df_sub_techniques = updated_df[updated_df[\"technique ID\"].str.contains(r\"\\.\\d+$\", regex=True)].copy()\n",
    "\n",
    "# Extract main techniques\n",
    "df_sub_techniques[\"main technique ID\"] = df_sub_techniques[\"technique ID\"].str.split(\".\").str[0]\n",
    "\n",
    "# Normalize text columns\n",
    "df_sub_techniques[\"technique name\"] = df_sub_techniques[\"technique name\"].str.strip().str.lower()\n",
    "df_sub_techniques[\"main technique ID\"] = df_sub_techniques[\"main technique ID\"].str.strip()\n",
    "\n",
    "# Encode IDs\n",
    "label_encoder_main = LabelEncoder()\n",
    "label_encoder_sub = LabelEncoder()\n",
    "df_sub_techniques[\"main technique ID\"] = label_encoder_main.fit_transform(df_sub_techniques[\"main technique ID\"])\n",
    "df_sub_techniques[\"technique ID\"] = label_encoder_sub.fit_transform(df_sub_techniques[\"technique ID\"])\n",
    "\n",
    "# Split data\n",
    "X = df_sub_techniques[[\"main technique ID\"]]\n",
    "y = df_sub_techniques[\"technique ID\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Check class distribution\n",
    "# print(\"Class distribution in y_train before filtering:\")\n",
    "# print(Counter(y_train))\n",
    "\n",
    "# Remove classes with fewer than 2 samples\n",
    "class_counts = y_train.value_counts()\n",
    "valid_classes = class_counts[class_counts > 1].index\n",
    "X_train_filtered = X_train[y_train.isin(valid_classes)]\n",
    "y_train_filtered = y_train[y_train.isin(valid_classes)]\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42, k_neighbors=1)  # Reduced neighbors to handle small classes\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# Train the model\n",
    "rf_classifier = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "rf_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Prediction function\n",
    "def predict_sub_techniques(main_technique_id):\n",
    "    \"\"\"Predict the sub-techniques for a given main technique.\"\"\"\n",
    "    main_technique_id = main_technique_id.strip()\n",
    "    if main_technique_id not in label_encoder_main.classes_:\n",
    "        return f\"Main technique ID '{main_technique_id}' not found.\"\n",
    "\n",
    "    encoded_main_technique = np.array([[label_encoder_main.transform([main_technique_id])[0]]])\n",
    "    predicted_sub_technique_class = rf_classifier.predict(encoded_main_technique)[0]\n",
    "    predicted_sub_technique = label_encoder_sub.inverse_transform([predicted_sub_technique_class])[0]\n",
    "    return f\"The predicted sub-technique for main technique '{main_technique_id}' is: {predicted_sub_technique}\"\n",
    "\n",
    "# Test the prediction function\n",
    "# example_main_technique_id = \"T1584\"\n",
    "# result = predict_sub_techniques(example_main_technique_id)\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7lMtKJDS71O"
   },
   "source": [
    "PLATFORMS EXPLOITED BY TECHNIQUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "cYlZc3LmSsV0",
    "outputId": "00274404-ea42-4cdd-9b4e-3d8d00932b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       Containers       1.00      0.92      0.96        65\n",
      "             IaaS       0.99      0.98      0.98        83\n",
      "Identity Provider       0.93      0.96      0.94        53\n",
      "            Linux       0.98      1.00      0.99       518\n",
      "          Network       0.97      0.97      0.97       179\n",
      "     Office Suite       0.92      0.98      0.95        61\n",
      "              PRE       0.92      0.94      0.93        65\n",
      "             SaaS       0.93      0.98      0.95        52\n",
      "          Windows       0.99      0.99      0.99       680\n",
      "            macOS       0.98      0.99      0.99       522\n",
      "\n",
      "        micro avg       0.98      0.99      0.98      2278\n",
      "        macro avg       0.96      0.97      0.97      2278\n",
      "     weighted avg       0.98      0.99      0.98      2278\n",
      "      samples avg       0.98      0.98      0.98      2278\n",
      "\n",
      "Model Accuracy: 96.42%\n",
      "Predicted platforms for technique 'Ingress Tool Transfer' ': [('Linux', 'Network', 'Windows', 'macOS')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tzhiq\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'updated_aptgroup_relationships.xlsx' # Replace with your file path\n",
    "df = pd.read_excel(file_path, sheet_name='updated_aptgroup_relationships')\n",
    "\n",
    "# Preprocess the 'technique platforms' column\n",
    "df['technique platforms'] = df['technique platforms'].str.split(', ')\n",
    "\n",
    "# Use MultiLabelBinarizer to encode multiple platforms\n",
    "mlb = MultiLabelBinarizer()\n",
    "platforms_encoded = mlb.fit_transform(df['technique platforms'])\n",
    "\n",
    "# Encode categorical features (e.g., techniques, group names)\n",
    "le_techniques = LabelEncoder()\n",
    "le_group = LabelEncoder()\n",
    "\n",
    "df['encoded_tech'] = le_techniques.fit_transform(df['technique name'])\n",
    "# df['encoded_group'] = le_group.fit_transform(df['group name'])\n",
    "\n",
    "# Combine features for the model\n",
    "X = df[['encoded_tech']]\n",
    "y = platforms_encoded\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=None)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "report = classification_report(y_test, y_pred, target_names=mlb.classes_)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Compute and display accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Optional: Save the model and encoders for future use\n",
    "import pickle\n",
    "with open('rf_model.pkl', 'wb') as model_file: # Replace with your file path\n",
    "    pickle.dump(rf_model, model_file)\n",
    "with open('mlb_encoder.pkl', 'wb') as mlb_file: # Replace with your file path\n",
    "    pickle.dump(mlb, mlb_file)\n",
    "with open('techniques_encoder.pkl', 'wb') as techniques_file: # Replace with your file path\n",
    "    pickle.dump(le_techniques, techniques_file)\n",
    "with open('group_encoder.pkl', 'wb') as group_file: # Replace with your file path\n",
    "    pickle.dump(le_group, group_file)\n",
    "\n",
    "# ====== TESTING SECTION ======\n",
    "\n",
    "# Example test input\n",
    "test_technique = \"Ingress Tool Transfer\"  # Replace with desired tech\n",
    "# test_group = \"APT-C-36\"       # Replace with desired group name\n",
    "\n",
    "# Encode the test input\n",
    "encoded_technique = le_techniques.transform([test_technique])[0]\n",
    "# encoded_group = le_group.transform([test_group])[0]\n",
    "\n",
    "# Create input for the model\n",
    "test_input = [[encoded_technique]]\n",
    "\n",
    "# Predict platforms\n",
    "predicted_platforms = rf_model.predict(test_input)\n",
    "\n",
    "# Decode the predicted platforms\n",
    "decoded_platforms = mlb.inverse_transform(predicted_platforms)\n",
    "print(f\"Predicted platforms for technique '{test_technique}' ': {decoded_platforms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZJWFPhCS15a"
   },
   "source": [
    "WHICH GROUP USE WHICH TECH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CwlK1OxES0B8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 11.44%\n",
      "The following APT groups are predicted to use the technique 'Malicious File':\n",
      "Windshift (probability: 0.02)\n",
      "Molerats (probability: 0.02)\n",
      "Sidewinder (probability: 0.01)\n",
      "FIN8 (probability: 0.01)\n",
      "Elderwood (probability: 0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tzhiq\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'updated_aptgroup_relationships.xlsx' # Replace with your file path\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Filter relevant columns and drop NaN values for training\n",
    "df = df.dropna(subset=[\"technique name\", \"group name\"])\n",
    "\n",
    "# Encode the \"group name\" and \"technique name\" columns\n",
    "group_name_encoder = LabelEncoder()\n",
    "technique_name_encoder = LabelEncoder()\n",
    "\n",
    "df[\"group name\"] = group_name_encoder.fit_transform(df[\"group name\"])\n",
    "df[\"technique name\"] = technique_name_encoder.fit_transform(df[\"technique name\"])\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df[[\"technique name\"]]\n",
    "y = df[\"group name\"]\n",
    "\n",
    "# Train a RandomForestClassifier with the technique names as input\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X, y)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "y_pred = rf_classifier.predict(X)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Define a function to predict groups based on technique names\n",
    "def predict_groups_by_technique_name(technique_name_input):\n",
    "    \"\"\"Predict up to 5 APT groups for a given technique name.\"\"\"\n",
    "    if technique_name_input not in technique_name_encoder.classes_:\n",
    "        return f\"Technique '{technique_name_input}' not found in the dataset.\"\n",
    "\n",
    "    # Encode the input technique name\n",
    "    encoded_technique_name = technique_name_encoder.transform([technique_name_input])[0]\n",
    "\n",
    "    # Predict probabilities for all classes\n",
    "    probabilities = rf_classifier.predict_proba([[encoded_technique_name]])[0]\n",
    "\n",
    "    # Get indices of top 5 probabilities\n",
    "    top_indices = probabilities.argsort()[-5:][::-1]\n",
    "    predicted_groups = group_name_encoder.inverse_transform(top_indices)\n",
    "    predicted_probs = [probabilities[i] for i in top_indices]\n",
    "\n",
    "    # Format the results\n",
    "    results = [\n",
    "        f\"{group} (probability: {prob:.2f})\"\n",
    "        for group, prob in zip(predicted_groups, predicted_probs)\n",
    "    ]\n",
    "\n",
    "    return f\"The following APT groups are predicted to use the technique '{technique_name_input}':\\n\" + \"\\n\".join(results)\n",
    "\n",
    "# Test the function with an example input\n",
    "example_technique = \"Malicious File\"\n",
    "response = predict_groups_by_technique_name(example_technique)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
